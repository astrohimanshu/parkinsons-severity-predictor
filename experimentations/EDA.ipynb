{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ─────────────────────────────────────────────\n",
    "# 1. LOAD\n",
    "# ─────────────────────────────────────────────\n",
    "df = pd.read_csv(\"../src/data/parkinsons_updrs.csv\")\n",
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# 2. EDA\n",
    "# ─────────────────────────────────────────────\n",
    "print(\"=== Missing Values ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n=== Basic Stats ===\")\n",
    "print(df.describe().T)\n",
    "\n",
    "# Target distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "for ax, col in zip(axes, [\"motor_UPDRS\", \"total_UPDRS\"]):\n",
    "    ax.hist(df[col], bins=40, color=\"#2196F3\", edgecolor=\"white\", alpha=0.85)\n",
    "    ax.set_title(f\"Distribution of {col}\", fontsize=13)\n",
    "    ax.set_xlabel(col); ax.set_ylabel(\"Count\")\n",
    "plt.tight_layout(); plt.savefig(\"eda_target_dist.png\", dpi=150); plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "corr = df.drop(columns=[\"subject#\", \"test_time\"]).corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, mask=mask, cmap=\"coolwarm\", center=0,\n",
    "            annot=False, linewidths=0.3, square=True)\n",
    "plt.title(\"Feature Correlation Matrix\", fontsize=14)\n",
    "plt.tight_layout(); plt.savefig(\"eda_corr_heatmap.png\", dpi=150); plt.show()\n",
    "\n",
    "# Correlation with targets\n",
    "target_corr = corr[[\"motor_UPDRS\", \"total_UPDRS\"]].drop(\n",
    "    [\"motor_UPDRS\", \"total_UPDRS\"]).sort_values(\"total_UPDRS\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 7))\n",
    "for ax, col in zip(axes, [\"motor_UPDRS\", \"total_UPDRS\"]):\n",
    "    target_corr[col].plot(kind=\"barh\", ax=ax, color=[\n",
    "        \"#EF5350\" if v < 0 else \"#42A5F5\" for v in target_corr[col]])\n",
    "    ax.set_title(f\"Feature Correlation → {col}\")\n",
    "    ax.axvline(0, color=\"black\", linewidth=0.8)\n",
    "plt.tight_layout(); plt.savefig(\"eda_target_corr.png\", dpi=150); plt.show()\n",
    "\n",
    "# Pairplot: top 5 features most correlated with total_UPDRS\n",
    "top5 = target_corr[\"total_UPDRS\"].abs().nlargest(5).index.tolist()\n",
    "sns.pairplot(df[top5 + [\"total_UPDRS\"]], diag_kind=\"kde\",\n",
    "             plot_kws={\"alpha\": 0.3, \"s\": 10})\n",
    "plt.suptitle(\"Top-5 Features vs total_UPDRS\", y=1.02)\n",
    "plt.savefig(\"eda_pairplot.png\", dpi=120); plt.show()\n",
    "\n",
    "# Boxplots per subject to catch inter-subject variability\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for ax, col in zip(axes, [\"motor_UPDRS\", \"total_UPDRS\"]):\n",
    "    df.boxplot(column=col, by=\"subject#\", ax=ax, \n",
    "               flierprops=dict(markersize=2, alpha=0.3))\n",
    "    ax.set_title(f\"{col} per Subject\")\n",
    "    ax.set_xlabel(\"Subject #\"); plt.sca(ax); plt.xticks(fontsize=6)\n",
    "plt.suptitle(\"\"); plt.tight_layout()\n",
    "plt.savefig(\"eda_subject_boxplot.png\", dpi=150); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────\n",
    "# 3. FEATURE ABLATION FOR XGBOOST\n",
    "# ─────────────────────────────────────────────\n",
    "TARGET    = \"total_UPDRS\"          # swap to motor_UPDRS if needed\n",
    "DROP_COLS = [\"subject#\", \"test_time\", \"motor_UPDRS\", \"total_UPDRS\"]\n",
    "\n",
    "X = df.drop(columns=DROP_COLS)\n",
    "y = df[TARGET]\n",
    "FEATURES = X.columns.tolist()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc  = scaler.transform(X_test)\n",
    "\n",
    "# ── 3a. Baseline: all features ──────────────────\n",
    "def fit_eval(X_tr, X_te, y_tr, y_te, feature_names=None):\n",
    "    m = XGBRegressor(n_estimators=400, learning_rate=0.05,\n",
    "                     max_depth=6, subsample=0.8,\n",
    "                     colsample_bytree=0.8, random_state=42, n_jobs=-1)\n",
    "    m.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], verbose=False)\n",
    "    p = m.predict(X_te)\n",
    "    return {\n",
    "        \"model\": m,\n",
    "        \"MAE\":   mean_absolute_error(y_te, p),\n",
    "        \"R2\":    r2_score(y_te, p),\n",
    "        \"features\": feature_names or list(range(X_tr.shape[1]))\n",
    "    }\n",
    "\n",
    "baseline = fit_eval(X_train_sc, X_test_sc, y_train, y_test, FEATURES)\n",
    "print(f\"Baseline  |  MAE={baseline['MAE']:.4f}  R²={baseline['R2']:.4f}\")\n",
    "\n",
    "# ── 3b. XGBoost native feature importance ──────\n",
    "importances = pd.Series(\n",
    "    baseline[\"model\"].feature_importances_, index=FEATURES\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances.plot(kind=\"bar\", color=\"#42A5F5\", edgecolor=\"white\")\n",
    "plt.title(\"XGBoost Feature Importance (gain) — Baseline Model\")\n",
    "plt.ylabel(\"Importance\"); plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout(); plt.savefig(\"ablation_importance.png\", dpi=150); plt.show()\n",
    "\n",
    "# ── 3c. Leave-One-Out Ablation ─────────────────\n",
    "# Remove each feature one at a time; record MAE & R² change vs baseline\n",
    "ablation_records = []\n",
    "\n",
    "for feat in FEATURES:\n",
    "    remaining = [f for f in FEATURES if f != feat]\n",
    "    idx = [FEATURES.index(f) for f in remaining]\n",
    "    \n",
    "    res = fit_eval(\n",
    "        X_train_sc[:, idx], X_test_sc[:, idx],\n",
    "        y_train, y_test, remaining\n",
    "    )\n",
    "    ablation_records.append({\n",
    "        \"dropped\":     feat,\n",
    "        \"MAE\":         res[\"MAE\"],\n",
    "        \"R2\":          res[\"R2\"],\n",
    "        \"ΔMAE\":        res[\"MAE\"] - baseline[\"MAE\"],   # + = worse without it\n",
    "        \"ΔR2\":         res[\"R2\"]  - baseline[\"R2\"],    # - = worse without it\n",
    "    })\n",
    "\n",
    "ablation_df = pd.DataFrame(ablation_records).sort_values(\"ΔMAE\", ascending=False)\n",
    "print(\"\\n=== Leave-One-Out Ablation (sorted by ΔMAE) ===\")\n",
    "print(ablation_df.to_string(index=False))\n",
    "\n",
    "# Plot ΔMAE\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = [\"#EF5350\" if v > 0 else \"#66BB6A\" for v in ablation_df[\"ΔMAE\"]]\n",
    "plt.bar(ablation_df[\"dropped\"], ablation_df[\"ΔMAE\"], color=colors, edgecolor=\"white\")\n",
    "plt.axhline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\n",
    "plt.title(\"Leave-One-Out Ablation — ΔMAE when feature is removed\\n\"\n",
    "          \"(Red = model hurts without it | Green = model improves without it)\")\n",
    "plt.ylabel(\"ΔMAE vs baseline\")\n",
    "plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout()\n",
    "plt.savefig(\"ablation_LOO_mae.png\", dpi=150); plt.show()\n",
    "\n",
    "# Plot ΔR²\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors2 = [\"#EF5350\" if v < 0 else \"#66BB6A\" for v in ablation_df[\"ΔR2\"]]\n",
    "plt.bar(ablation_df[\"dropped\"], ablation_df[\"ΔR2\"], color=colors2, edgecolor=\"white\")\n",
    "plt.axhline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\n",
    "plt.title(\"Leave-One-Out Ablation — ΔR² when feature is removed\")\n",
    "plt.ylabel(\"ΔR² vs baseline\")\n",
    "plt.xticks(rotation=45, ha=\"right\"); plt.tight_layout()\n",
    "plt.savefig(\"ablation_LOO_r2.png\", dpi=150); plt.show()\n",
    "\n",
    "# ── 3d. Cumulative Ablation (greedy forward drop) ──\n",
    "# Drop least important feature one at a time, track performance\n",
    "sorted_feats = importances.index.tolist()[::-1]  # ascending importance\n",
    "remaining_feats = FEATURES.copy()\n",
    "cumulative = [{\"n_features\": len(FEATURES), \"MAE\": baseline[\"MAE\"],\n",
    "               \"R2\": baseline[\"R2\"], \"dropped\": None}]\n",
    "\n",
    "for feat in sorted_feats:\n",
    "    if len(remaining_feats) <= 2:\n",
    "        break\n",
    "    remaining_feats.remove(feat)\n",
    "    idx = [FEATURES.index(f) for f in remaining_feats]\n",
    "    res = fit_eval(X_train_sc[:, idx], X_test_sc[:, idx], y_train, y_test)\n",
    "    cumulative.append({\n",
    "        \"n_features\": len(remaining_feats),\n",
    "        \"MAE\": res[\"MAE\"], \"R2\": res[\"R2\"], \"dropped\": feat\n",
    "    })\n",
    "\n",
    "cum_df = pd.DataFrame(cumulative)\n",
    "print(\"\\n=== Cumulative Feature Removal ===\")\n",
    "print(cum_df.to_string(index=False))\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(cum_df[\"n_features\"], cum_df[\"MAE\"], \"o-\", color=\"#EF5350\", label=\"MAE\")\n",
    "ax2.plot(cum_df[\"n_features\"], cum_df[\"R2\"],  \"s--\", color=\"#42A5F5\", label=\"R²\")\n",
    "ax1.invert_xaxis()\n",
    "ax1.set_xlabel(\"Number of Features Remaining\")\n",
    "ax1.set_ylabel(\"MAE\", color=\"#EF5350\")\n",
    "ax2.set_ylabel(\"R²\",  color=\"#42A5F5\")\n",
    "ax1.axvline(cum_df.loc[cum_df[\"MAE\"].idxmin(), \"n_features\"],\n",
    "            color=\"gray\", linestyle=\":\", label=\"Best MAE point\")\n",
    "plt.title(\"Cumulative Ablation — Performance vs Feature Count\\n\"\n",
    "          \"(Features removed in order of lowest → highest importance)\")\n",
    "fig.legend(loc=\"upper left\", bbox_to_anchor=(0.1, 0.88))\n",
    "plt.tight_layout(); plt.savefig(\"ablation_cumulative.png\", dpi=150); plt.show()\n",
    "\n",
    "# ── 3e. Summary: recommended feature subset ────\n",
    "best_n = int(cum_df.loc[cum_df[\"MAE\"].idxmin(), \"n_features\"])\n",
    "best_row = cum_df[cum_df[\"n_features\"] == best_n].iloc[0]\n",
    "dropped_up_to_best = sorted_feats[:len(FEATURES) - best_n]\n",
    "recommended = [f for f in FEATURES if f not in dropped_up_to_best]\n",
    "\n",
    "print(f\"\\n✅ Recommended feature subset ({best_n} features)\")\n",
    "print(f\"   MAE={best_row['MAE']:.4f}  R²={best_row['R2']:.4f}\")\n",
    "print(\"   Features:\", recommended)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group-project-aml (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
